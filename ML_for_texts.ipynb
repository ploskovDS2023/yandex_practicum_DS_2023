{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* Над этим проектом нужно будет еще немного поработать. Однако, изменения не должны занять много времени.\n",
    "* С радостью отвечу на твои вопросы, если они есть. Лучше всего их собрать в следующей ячейке. Жду новую версию проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Для удобства все новые комментарии обозначены фразой \"ревью 2\".\n",
    "* Удачи в доработке!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 3)</font>\n",
    "* После исправлений проект улучшился и теперь он может быть зачтен.\n",
    "* Удачи в дальнейшем обучении и следующих работах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-3)\" data-toc-modified-id=\"Общее-впечатление-(ревью-3)-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 3)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from pymystem3 import Mystem\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для лемматизации текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WordNetLemmatizer()\n",
    "\n",
    "# def lemmatize_text(text):    \n",
    "#     text = text.lower() # приведение к нижнему регистру\n",
    "#     lemm_text = \"\".join(m.lemmatize(text)) \n",
    "#     cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) # очистка от лишних символов\n",
    "#     return \" \".join(cleared_text.split())\n",
    "\n",
    "# df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Создадим функцию которая будет использовать функцию по очистке слов и лемматизировать каждое слово\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['text'])\n",
    "\n",
    "def clear_text(text):\n",
    "    y=re.sub(r\"[^'a-zA-Z ]\", ' ', text) \n",
    "    k=\" \".join(y.split())\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c3975ff71748f288c388e14e537992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lemmafunction(textc):\n",
    "    k=[]\n",
    "    for i in nltk.word_tokenize(textc):\n",
    "        y=m.lemmatize(i, get_wordnet_pos(i))\n",
    "        k.append(y)\n",
    "    return ' '.join(k) \n",
    "\n",
    "lemy=[]\n",
    "for i in tqdm(range(len(corpus))):\n",
    "    \n",
    "    lemy.append(lemmafunction(clear_text(corpus[i])))\n",
    "df['lemm_text']=pd.Series(lemy, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка была сделана верно.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Ошибка:</b> WordNetLemmatizer лемматизатор нужно применять с соответствующим POS-тегом. Этот процесс подробно описан в абзаце \"Wordnet Lemmatizer с соответствующим POS-тегом\" в статье: https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Не разобрался пока с POS-тегом, заменил на Mystem. Спасибо за эту статью и остальные материалы, буду изучать, мне как раз интерессны NLP и трансформеры\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка (ревью 2):</b> Mystem работает только с русским языком, так что его нет смысла применять. Я бы использовал WordNetLemmatizer. Отмечу, что его нужно применять к словам, а не ко всему тексту сразу.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак и обучающий набор данных. Разделим на обучающию и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features = df.drop(['toxic'], axis=1)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,target,test_size=0.4,random_state=142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем стоп слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['text'].values)\n",
    "\n",
    "features_test = count_tf_idf.transform(features_test['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано верно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      " Лучшая метрика F1 = 0.6191617536336324  при параметрах {'criterion': 'gini', 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state = 142)\n",
    "\n",
    "grid_params = {\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':list(range(15,16))\n",
    "}\n",
    "\n",
    "tree_gs = GridSearchCV(tree,param_grid=grid_params, cv=3, scoring='f1', verbose=True).fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print(f' Лучшая метрика F1 = {tree_gs.best_score_}  при параметрах {tree_gs.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая метрика F1 = 0.6191617536336324  при параметрах {'criterion': 'gini', 'max_depth': 15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a> из векторизатора и модели. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный Лес:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      " Лучшая метрика F1 = 0.0006180469715698394  при параметрах {'max_depth': 15, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state = 142)\n",
    "\n",
    "params = {\n",
    "   'n_estimators':range(10,11),        \n",
    "   'max_depth':list(range(15,16)) \n",
    "}\n",
    "\n",
    "forest_gs = GridSearchCV(forest, param_grid=params, cv=3, scoring='f1', verbose=True).fit(features_train, target_train)\n",
    "\n",
    "print(f' Лучшая метрика F1 = {forest_gs.best_score_}  при параметрах {forest_gs.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая метрика F1 = 0.0006180469715698394  при параметрах {'max_depth': 15, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      " Лучшая метрика F1 = 0.7642854128290261  при параметрах {'C': 15.0, 'intercept_scaling': 15, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state = 142, class_weight='balanced')\n",
    "\n",
    "params = {       \n",
    "   'C':[15.0],\n",
    "    'intercept_scaling' : range(15,16),\n",
    "    'solver' : ['liblinear']\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(lr,param_grid=params, cv=3, scoring='f1', verbose=True).fit(features_train, target_train)\n",
    "\n",
    "print(f' Лучшая метрика F1 = {lr_gs.best_score_}  при параметрах {lr_gs.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая метрика F1 = 0.7642854128290261  при параметрах {'C': 15.0, 'intercept_scaling': 15, 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что попробовал разные модели в этом шаге!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Лучшая модель - Логистической регрессии, проверим ее на тестовой выборке:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_predictions = tree_gs.predict(features_test)\n",
    "# print(f1_score(target_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_predictions = forest_gs.predict(features_test)\n",
    "# print(f1_score(target_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7609258300672928\n"
     ]
    }
   ],
   "source": [
    "dt_predictions = lr_gs.predict(features_test)\n",
    "print(f1_score(target_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Ошибка:</b> На тестовой выборке нужно измерить только одну – лучшую модель. Сравнение моделей нужно провести только на кросс-валидации `grid.best_score_` (с одним и тем же параметром \"cv\") или только на валидационной выборке.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех (ревью 2):</b> ОК.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\\\n",
    " Были обучены разные модели классификации комментариев на позитивные и негативные. В нашем распоряжении был набор данных с разметкой о токсичности правок.\\\n",
    " Самой эффективной моделью, которая показала максимальную метрику F1(0.76) оказалась модель Логистической регресии. Условие построить модель со значением метрики качества F1 не меньше 0.75 выполнено. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть вывод в конце проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 421,
    "start_time": "2023-07-24T12:25:23.452Z"
   },
   {
    "duration": 3492,
    "start_time": "2023-07-24T12:25:45.875Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-24T12:25:59.486Z"
   },
   {
    "duration": 33,
    "start_time": "2023-07-24T12:26:07.962Z"
   },
   {
    "duration": 1322,
    "start_time": "2023-07-25T11:42:00.323Z"
   },
   {
    "duration": 3383,
    "start_time": "2023-07-25T11:42:06.124Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-25T11:42:09.508Z"
   },
   {
    "duration": 43,
    "start_time": "2023-07-25T11:42:09.528Z"
   },
   {
    "duration": 7161,
    "start_time": "2023-07-25T11:42:30.069Z"
   },
   {
    "duration": 127,
    "start_time": "2023-07-25T11:42:56.926Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-25T11:43:19.913Z"
   },
   {
    "duration": 34,
    "start_time": "2023-07-25T11:43:23.157Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-25T11:43:52.181Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-25T11:44:11.606Z"
   },
   {
    "duration": 237,
    "start_time": "2023-07-25T11:44:17.065Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-25T11:44:42.895Z"
   },
   {
    "duration": 6682,
    "start_time": "2023-07-25T11:44:45.950Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-25T11:45:17.020Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-25T11:45:33.742Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-25T11:45:37.728Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-25T11:45:58.069Z"
   },
   {
    "duration": 52436,
    "start_time": "2023-07-25T11:46:02.056Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-25T11:47:31.327Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-25T11:47:50.407Z"
   },
   {
    "duration": 5342,
    "start_time": "2023-07-25T11:47:54.671Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-25T11:49:24.325Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-25T11:49:46.366Z"
   },
   {
    "duration": 93751,
    "start_time": "2023-07-25T11:49:51.365Z"
   },
   {
    "duration": 39,
    "start_time": "2023-07-25T11:52:27.734Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-25T11:53:39.123Z"
   },
   {
    "duration": 46,
    "start_time": "2023-07-25T11:53:45.215Z"
   },
   {
    "duration": 129,
    "start_time": "2023-07-25T11:54:22.934Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-25T11:54:43.332Z"
   },
   {
    "duration": 5537,
    "start_time": "2023-07-25T12:26:55.322Z"
   },
   {
    "duration": 92088,
    "start_time": "2023-07-25T12:27:35.426Z"
   },
   {
    "duration": 47,
    "start_time": "2023-07-26T18:38:01.106Z"
   },
   {
    "duration": 1302,
    "start_time": "2023-07-26T18:38:06.602Z"
   },
   {
    "duration": 78,
    "start_time": "2023-07-26T18:38:13.804Z"
   },
   {
    "duration": 3343,
    "start_time": "2023-07-26T18:38:19.353Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-26T18:38:24.833Z"
   },
   {
    "duration": 37,
    "start_time": "2023-07-26T18:38:26.716Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-26T18:38:30.521Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-26T18:38:51.393Z"
   },
   {
    "duration": 94,
    "start_time": "2023-07-26T18:39:14.506Z"
   },
   {
    "duration": 26,
    "start_time": "2023-07-26T18:39:20.301Z"
   },
   {
    "duration": 239,
    "start_time": "2023-07-26T18:39:56.370Z"
   },
   {
    "duration": 6615,
    "start_time": "2023-07-26T18:40:14.611Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-26T18:41:00.711Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-26T18:41:55.270Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-26T18:42:35.429Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-26T18:42:45.139Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-26T18:43:55.854Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-26T18:44:05.415Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-26T18:49:58.219Z"
   },
   {
    "duration": 4504,
    "start_time": "2023-07-26T18:50:01.956Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-26T18:50:09.860Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-26T18:50:43.022Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-26T18:51:16.509Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-26T18:51:31.580Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-26T18:51:44.329Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-26T18:52:36.800Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-26T18:53:51.117Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-26T18:53:56.837Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-26T18:54:25.227Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-26T18:54:41.800Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-26T18:54:46.012Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-26T18:55:10.520Z"
   },
   {
    "duration": 1516,
    "start_time": "2023-07-26T22:28:51.087Z"
   },
   {
    "duration": 138,
    "start_time": "2023-07-26T22:29:20.087Z"
   },
   {
    "duration": 1502,
    "start_time": "2023-07-26T22:29:29.077Z"
   },
   {
    "duration": 3093,
    "start_time": "2023-07-26T22:29:30.581Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-26T22:29:33.676Z"
   },
   {
    "duration": 46,
    "start_time": "2023-07-26T22:29:33.696Z"
   },
   {
    "duration": 183,
    "start_time": "2023-07-26T22:29:33.744Z"
   },
   {
    "duration": 104618,
    "start_time": "2023-07-26T22:29:33.929Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-26T22:31:18.550Z"
   },
   {
    "duration": 181,
    "start_time": "2023-07-26T22:31:18.556Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.739Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.740Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.741Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.742Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.743Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.752Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.754Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-26T22:31:18.755Z"
   },
   {
    "duration": 49,
    "start_time": "2023-07-26T22:31:23.823Z"
   },
   {
    "duration": 7868,
    "start_time": "2023-07-26T22:31:29.074Z"
   },
   {
    "duration": 56972,
    "start_time": "2023-07-26T22:37:21.998Z"
   },
   {
    "duration": 5825,
    "start_time": "2023-07-26T22:39:07.004Z"
   },
   {
    "duration": 100117,
    "start_time": "2023-07-26T22:39:38.848Z"
   },
   {
    "duration": 117,
    "start_time": "2023-07-26T22:43:02.040Z"
   },
   {
    "duration": 28,
    "start_time": "2023-07-26T22:44:35.581Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-27T22:04:03.292Z"
   },
   {
    "duration": 43,
    "start_time": "2023-07-27T22:04:26.867Z"
   },
   {
    "duration": 1674,
    "start_time": "2023-07-27T22:04:48.465Z"
   },
   {
    "duration": 89,
    "start_time": "2023-07-27T22:04:55.386Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-27T22:06:18.684Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-27T22:06:38.062Z"
   },
   {
    "duration": 1361,
    "start_time": "2023-07-27T22:06:46.185Z"
   },
   {
    "duration": 3430,
    "start_time": "2023-07-27T22:06:47.548Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-27T22:06:50.979Z"
   },
   {
    "duration": 33,
    "start_time": "2023-07-27T22:06:50.993Z"
   },
   {
    "duration": 227,
    "start_time": "2023-07-27T22:06:51.028Z"
   },
   {
    "duration": 6452,
    "start_time": "2023-07-27T22:06:51.257Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-27T22:06:57.712Z"
   },
   {
    "duration": 146,
    "start_time": "2023-07-27T22:06:57.718Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.866Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.875Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.877Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.878Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.879Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.881Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.882Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-27T22:06:57.884Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-27T22:07:26.554Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-27T22:08:27.193Z"
   },
   {
    "duration": 831,
    "start_time": "2023-07-27T22:08:29.456Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-27T22:08:32.357Z"
   },
   {
    "duration": 32,
    "start_time": "2023-07-27T22:08:33.391Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-27T22:08:37.511Z"
   },
   {
    "duration": 5438,
    "start_time": "2023-07-27T22:08:39.394Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-27T22:08:47.206Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-27T22:08:48.755Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-27T22:09:37.689Z"
   },
   {
    "duration": 319,
    "start_time": "2023-07-27T22:10:05.194Z"
   },
   {
    "duration": 4748,
    "start_time": "2023-07-27T22:10:07.765Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-27T22:10:12.515Z"
   },
   {
    "duration": 102,
    "start_time": "2023-07-27T22:10:15.204Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-27T22:10:54.189Z"
   },
   {
    "duration": 797,
    "start_time": "2023-07-27T22:11:14.782Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-27T22:11:16.668Z"
   },
   {
    "duration": 31,
    "start_time": "2023-07-27T22:11:17.516Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-27T22:11:26.104Z"
   },
   {
    "duration": 5410,
    "start_time": "2023-07-27T22:11:27.566Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-27T22:11:44.879Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-27T22:11:45.987Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-27T22:21:13.018Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-27T22:21:32.830Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-27T22:22:13.114Z"
   },
   {
    "duration": 40,
    "start_time": "2023-07-27T22:22:22.658Z"
   },
   {
    "duration": 40,
    "start_time": "2023-07-27T22:24:29.804Z"
   },
   {
    "duration": 86,
    "start_time": "2023-07-27T22:25:05.725Z"
   },
   {
    "duration": 84,
    "start_time": "2023-07-27T22:25:28.213Z"
   },
   {
    "duration": 85,
    "start_time": "2023-07-27T22:25:33.671Z"
   },
   {
    "duration": 82,
    "start_time": "2023-07-27T22:25:39.592Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-27T22:26:21.149Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-27T22:26:26.445Z"
   },
   {
    "duration": 42,
    "start_time": "2023-07-27T22:27:21.847Z"
   },
   {
    "duration": 33,
    "start_time": "2023-07-27T22:27:27.398Z"
   },
   {
    "duration": 34,
    "start_time": "2023-07-27T22:27:57.246Z"
   },
   {
    "duration": 43,
    "start_time": "2023-07-27T22:28:10.077Z"
   },
   {
    "duration": 1096289,
    "start_time": "2023-07-27T22:28:21.620Z"
   },
   {
    "duration": 1102126,
    "start_time": "2023-07-27T22:47:26.416Z"
   },
   {
    "duration": 66,
    "start_time": "2023-07-27T23:07:35.674Z"
   },
   {
    "duration": 7184,
    "start_time": "2023-07-27T23:07:37.424Z"
   },
   {
    "duration": 53356,
    "start_time": "2023-07-27T23:07:48.618Z"
   },
   {
    "duration": 6247,
    "start_time": "2023-07-27T23:10:38.570Z"
   },
   {
    "duration": 100722,
    "start_time": "2023-07-27T23:11:11.470Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-27T23:13:16.013Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
